{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection exercises\n",
    "\n",
    "How do we measure the performance of a feature selection algorithm? This is a difficult question and we should consider a few aspects of the answer:\n",
    "- computation time\n",
    "- size of the resulting feature set (the minimal description length principle)\n",
    "- feature set stability (whether the set of selected features changes a lot when we slightly change our data)\n",
    "- performance of prediction models (the ability to identify valid dependencies in the data)\n",
    "\n",
    "There are several popular methods of testing the FS performance. \n",
    "1. The best way - compare the resulting feature sets to the ground truth. Unfortunately, in practice, this is possible only for synthetic data or relatively simple data that can be analyzed by experts.\n",
    "2. If we cannot directly compare with the ground truth, then we can at least estimate how often a given algorithm makes obvious errors. One way of doing that is to artificially add a set of random probes to the data before we start our analysis and check what portion of the selected features comes from this set.\n",
    "3. We may draw several bootstrap samples of data a empirically check the stability of FS.\n",
    "4. We may assess the FS algorithm indirectly by estimating the performance of a prediction algorithm that uses the selected features. **This method requires caution**. We must not use the same data for FS and the estimation!\n",
    "\n",
    "## Gollub's experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of k-NN is:  0.72 \n"
     ]
    }
   ],
   "source": [
    "library(class)\n",
    "nRows = 100\n",
    "nCols = 10000\n",
    "\n",
    "# Let's generate some random data...\n",
    "dataTab = as.data.frame(matrix(runif(nRows*nCols, -1, 1), nRows, nCols))\n",
    "# and a random decision vector\n",
    "decisionClasses = sample(c(0,1), nRows, replace = TRUE)\n",
    "# we may rank the features using any method, e.g. correlation filter, and select the top 5\n",
    "corScores = abs(cor(dataTab, decisionClasses))\n",
    "selectedAttrs = order(corScores, decreasing = TRUE)[1:5]\n",
    "\n",
    "# now, we can measure performance of a prediction model\n",
    "predsAll = knn.cv(dataTab[selectedAttrs], decisionClasses, k = 3)\n",
    "cat('The accuracy of k-NN is: ', mean(as.character(decisionClasses) == as.character(predsAll)), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you say about the above results? As the first exercise, please repeat the experiment using a proper methodology. Compare the outcomes. What are your conclusions?\n",
    "\n",
    "## An experiment with synthetic data\n",
    "\n",
    "Let's define another synthetic data but this time, let's make the classification vector dependent on the first 10 attributes (see the examples below). Try to assess the performance of the discussed feature subset selection methods with regard to the difficulty (complexity) of the decision attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decisions1\n",
       "  0   1 \n",
       "513 487 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "decisions2\n",
       "  0   1 \n",
       "603 397 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "decisions3\n",
       "  0   1 \n",
       "569 431 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>decisions1</th><th scope=col>decisions2</th><th scope=col>decisions3</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>decisions1</th><td> 1.00000000</td><td>-0.09134539</td><td> 0.01253614</td></tr>\n",
       "\t<tr><th scope=row>decisions2</th><td>-0.09134539</td><td> 1.00000000</td><td>-0.05409469</td></tr>\n",
       "\t<tr><th scope=row>decisions3</th><td> 0.01253614</td><td>-0.05409469</td><td> 1.00000000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & decisions1 & decisions2 & decisions3\\\\\n",
       "\\hline\n",
       "\tdecisions1 &  1.00000000 & -0.09134539 &  0.01253614\\\\\n",
       "\tdecisions2 & -0.09134539 &  1.00000000 & -0.05409469\\\\\n",
       "\tdecisions3 &  0.01253614 & -0.05409469 &  1.00000000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | decisions1 | decisions2 | decisions3 | \n",
       "|---|---|---|\n",
       "| decisions1 |  1.00000000 | -0.09134539 |  0.01253614 | \n",
       "| decisions2 | -0.09134539 |  1.00000000 | -0.05409469 | \n",
       "| decisions3 |  0.01253614 | -0.05409469 |  1.00000000 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "           decisions1  decisions2  decisions3 \n",
       "decisions1  1.00000000 -0.09134539  0.01253614\n",
       "decisions2 -0.09134539  1.00000000 -0.05409469\n",
       "decisions3  0.01253614 -0.05409469  1.00000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nRows = 1000\n",
    "nCols = 100\n",
    "\n",
    "# Let's generate some random data...\n",
    "dataTab = as.data.frame(matrix(runif(nRows*nCols, -1, 1), nRows, nCols))\n",
    "\n",
    "decisions1 = apply(dataTab, 1, function(x) as.integer(sum(x[1:10]) > 0))\n",
    "# introduce some noise\n",
    "tmp = sample(nRows, 150)\n",
    "decisions1[tmp] = abs(decisions1[tmp] - 1)\n",
    "table(decisions1)\n",
    "                   \n",
    "decisions2 = apply(dataTab, 1, \n",
    "                   function(x) as.integer((x[1] > 0 & x[2] > 0 & x[3] < 0) | (x[3] > 0 & sum(x[4:10]) < 0)))\n",
    "tmp = sample(nRows, 150)\n",
    "decisions2[tmp] = abs(decisions2[tmp] - 1)\n",
    "table(decisions2)\n",
    "                   \n",
    "decisions3 = apply(dataTab, 1, \n",
    "                   function(x) as.integer((sum(x[1:4]) < 0.5 & sum(x[1:4]) > -0.5 & \n",
    "                                           sum(x[5:8]) < 0.5 & sum(x[5:8]) > -0.5) |\n",
    "                                          (x[9] < 0.5 & x[9] > -0.5 & abs(x[10] * x[1]) < 0.25)))\n",
    "tmp = sample(nRows, 150)\n",
    "decisions3[tmp] = abs(decisions3[tmp] - 1)\n",
    "table(decisions3)\n",
    "\n",
    "cor(cbind(decisions1, decisions2, decisions3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A real-world example - a microarray data set\n",
    "\n",
    "In this task, you will have to face the curse of dimensionality. Your task is to analyze the *acuteLymphoblasticLeukemia* data. Use some of the techniques we discussed (choose a few) to select and evaluate sets of genes that allow classifying cases of leukemia into subtypes.\n",
    "\n",
    "Choose your FS algorithms wisely as not all of the discussed methods are computationally feasible in this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Read 0.0% of 190 rows\r",
      "Read 190 rows and 22278 (of 22278) columns from 0.048 GB file in 00:00:06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>190</li>\n",
       "\t<li>22278</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 190\n",
       "\\item 22278\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 190\n",
       "2. 22278\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]   190 22278"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Decision'</li>\n",
       "\t<li>'AFFX-BioB-3_at'</li>\n",
       "\t<li>'AFFX-BioB-5_at'</li>\n",
       "\t<li>'AFFX-BioB-M_at'</li>\n",
       "\t<li>'AFFX-BioC-3_at'</li>\n",
       "\t<li>'AFFX-BioC-5_at'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Decision'\n",
       "\\item 'AFFX-BioB-3\\_at'\n",
       "\\item 'AFFX-BioB-5\\_at'\n",
       "\\item 'AFFX-BioB-M\\_at'\n",
       "\\item 'AFFX-BioC-3\\_at'\n",
       "\\item 'AFFX-BioC-5\\_at'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Decision'\n",
       "2. 'AFFX-BioB-3_at'\n",
       "3. 'AFFX-BioB-5_at'\n",
       "4. 'AFFX-BioB-M_at'\n",
       "5. 'AFFX-BioC-3_at'\n",
       "6. 'AFFX-BioC-5_at'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Decision\"       \"AFFX-BioB-3_at\" \"AFFX-BioB-5_at\" \"AFFX-BioB-M_at\"\n",
       "[5] \"AFFX-BioC-3_at\" \"AFFX-BioC-5_at\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'222379_at'</li>\n",
       "\t<li>'222380_s_at'</li>\n",
       "\t<li>'222381_at'</li>\n",
       "\t<li>'222382_x_at'</li>\n",
       "\t<li>'222383_s_at'</li>\n",
       "\t<li>'222384_at'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '222379\\_at'\n",
       "\\item '222380\\_s\\_at'\n",
       "\\item '222381\\_at'\n",
       "\\item '222382\\_x\\_at'\n",
       "\\item '222383\\_s\\_at'\n",
       "\\item '222384\\_at'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '222379_at'\n",
       "2. '222380_s_at'\n",
       "3. '222381_at'\n",
       "4. '222382_x_at'\n",
       "5. '222383_s_at'\n",
       "6. '222384_at'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"222379_at\"   \"222380_s_at\" \"222381_at\"   \"222382_x_at\" \"222383_s_at\"\n",
       "[6] \"222384_at\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " Precursor-B  ALL, subtype: Hyperdiploid \n",
       "                                      44 \n",
       "Precursor-B ALL, subtype: E2A-rearranged \n",
       "                                      13 \n",
       "         Precursor-B ALL, subtype: other \n",
       "                                      53 \n",
       "      Precursor-B ALL, subtype: TEL-AML1 \n",
       "                                      44 \n",
       "                                   T-ALL \n",
       "                                      36 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(data.table)\n",
    "\n",
    "leukemiaDT = data.table::fread('acuteLymphoblasticLeukemia.data', header = TRUE)\n",
    "dim(leukemiaDT)\n",
    "head(colnames(leukemiaDT))\n",
    "tail(colnames(leukemiaDT))\n",
    "\n",
    "table(leukemiaDT$Decision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
